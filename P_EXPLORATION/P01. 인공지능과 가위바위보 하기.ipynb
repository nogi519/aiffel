{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><span style=\"color:#2C786C\">프로젝트 : 가위바위보 분류기 만들기</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오늘 배운 내용을 바탕으로 가위바위보 분류기를 만들도록 하겠습니다. 가장 먼저 해야 할 일은 뭘까요? 네, 첫 번째!!!! 데이터를 준비해야 합니다. 가위바위보 이미지를 모아 놓은 곳은 없으므로, 우리가 직접 사진을 찍어서 모아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#F7B400\">순서</span>\n",
    "> **<span style=\"color:#2C786C\">Step 1. 데이터를 준비하자</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 2. 딥러닝 네트워크 설계하기</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 3. 딥러닝 네트워크 학습시키기</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 4. 얼마나 잘 만들었는지 확인하기(테스트)</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 5. 더 좋은 네트워크 만들어보기</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 6. 노드를 마치며...</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 7. 루브릭 평가</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 8. 회고</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#926DD6\">참고</span>\n",
    ">* **<span style=\"color:#DD94B9\">토닥토닥 파이썬 - 이미지를 위한 딥러닝 (텐서플로우 v1)(wikidocs) :** [네이버 영화 리뷰 감성 분류하기(Naver Movie Review Sentiment Analysis)](https://wikidocs.net/63061)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#926DD6\">용어 정리</span>\n",
    "> **<span style=\"color:#492569\">✓ 텐서플로우(TensorFlow)란?**\n",
    ">* 가장 널리 사용되고 있는 머신러닝 라이브러리 중 하나\n",
    ">* 구글(Google)에서 오픈소스로 제공, 대부분의 딥러닝 구현실습은 Tensorflow 버전 2.0(=TF 2.0, 혹은 그 이상)에서 진행될 예정!\n",
    "\n",
    "> <span style=\"color:#492569\">**✓ Matplotlib이란?**</span>\n",
    ">* 파이썬에서 제공하는 시각화(Visualization) 패키지\n",
    ">* 차트(chart), 플롯(plot) 등 다양한 형태로 데이터를 시각화할 수 있는 강력한 기능을 제공\n",
    ">* 참고 : [Matplotlib활용사례 보기](https://matplotlib.org/2.0.2/gallery.html)\n",
    "\n",
    "> **<span style=\"color:#492569\">✓ data set이란?**</span>\n",
    ">* 자료의 모임\n",
    ">* 참고 : [데이터셋 이야기](https://tykimos.github.io/2017/03/25/Dataset_and_Fit_Talk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어떻게 만들까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 딥러닝 기술은 **\"데이터 준비 → 딥러닝 네트워크 설계 → 학습 → 테스트(평가)\"** 의 순서대로 만들게 되는데 이 과정을 따라 만들어 보겠습니다.\n",
    "그렇다면 가장 먼저 해야 할 일은 뭘까요?  \n",
    "**네, 첫 번째!!!! 데이터를 준비해야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 1. 데이터를 준비하자</span>\n",
    "---\n",
    "### 데이터 만들기\n",
    "\n",
    "(1) 우리는 노트북 전면 카메라를 활용하여 가위, 바위, 보 이미지 각 100장을 만들어 볼거예요. 그런데 300장을 어느 세월에 만들까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/E-1-8.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "걱정하지 마세요. 구글의 teachable machine 사이트에서 쉽게 데이터를 만들어볼 수 있습니다. 아래 사이트에서 Get Started 버튼을 눌러보세요. 그 다음, Image Project를 선택하면 Webcam을 구동해 클래스별 이미지 데이터를 직접 촬영해서 만들 수 있는 멋진 화면이 나타납니다.\n",
    "* https://teachablemachine.withgoogle.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 먼저 가위 이미지 데이터를 만들어 봅시다. 웹캠 앞에 가위 포즈를 취하면서 버튼을 누르면 이미지가 캡쳐됩니다. 딥러닝 모델이 인식하기 좋게끔 여러분들 손이 잘 보이게 찍어주세요.\n",
    "\n",
    "* 여러 각도에서 찍어보세요.\n",
    "* 여러 크기로 찍어보세요.\n",
    "* 혼자하면 다양한 각도와 크기를 저장할 수 없으니, 옆 동료와 함께 하세요.\n",
    "* 좋은 데이터가 좋은 결과를 낳는다는 것을 꼭 기억하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/E-1-9.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의] 만약 웹캠 사용 버튼을 눌렀을 때 아래 화면처럼 에러가 난다면, 브라우저에서 웹캠을 사용할 수 있는 권한을 허용해 주어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://aiffelstaticprd.blob.core.windows.net/media/images/E-1-10.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 100장의 가위 이미지를 캡쳐했다면, 우상단의 메뉴 아이콘을 눌러 다운로드 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-1-11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 가위 이미지 100장을 모두 저장 했다면, 바위 및 보 이미지에 대해서도 위 과정을 진행하세요. 가위는 scissor 폴더에, 바위는 rock 폴더에, 보는 paper 폴더에 각각 압축을 풀어 봅시다. 각 폴더안에 100개의 이미지가 들어있다면 성공!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추후 프로그램 작성의 통일성을 위해, rock_scissor_paper 라는 폴더 아래에 scissor, rock, paper 폴더를 만들어서 이미지를 저장합시다. 각 이미지는 아래 폴더 안에 들어가야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디렉토리 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본인의 환경에 따라 실습용 디렉토리 rock_scissor_paper 및 하위 디렉토리를 만들어 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저는 터미널로 설치했습니다.\n",
    "\n",
    "# mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "# mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "# mkdir -p ~/aiffel/rock_scissor_paper/paper \n",
    "\n",
    "# ls -l ~/aiffel/rock_scissor_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가위, 바위, 보 이미지를 28x28로 만들어야 합니다. 이를 위해서는 PIL 라이브러리를 사용해볼 건데 혹시 PIL 라이브러리가 없는 경우 필요한 패키지를 설치해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# pip install pillow   # PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 가위, 바위, 보 이미지를 불러와서 28x28 사이즈로 변경할 겁니다. 아래 코드를 실행하여 이미지의 크기를 28x28 로 바꾸겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다. (데이터 전처리)\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_data() 함수는 입력으로 이미지가 있는 폴더 위치를 받습니다.  \n",
    "여기서는 **rock_scissor_paper** 폴더 위치를 적어주면 됩니다.  \n",
    "가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링이 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, name):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32) # 임폴트한 numpy 사용\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*'): # *는 jpg, jpeg 모두 불러오기\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터({})의 이미지 개수는 {}입니다.\".format(name,idx))\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path, \"x_train\")\n",
    "\n",
    "x_train_norm = x_train/255.0   # 255로 나눠서 정규화\n",
    "# y_train_norm = y_train # 이미지가 아닌 x_train_norm에 대한 라벨이 들어가 있으므로 주석처리\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape)) # 실제 이미지가 들어있음\n",
    "print(\"y_train shape: {}\".format(y_train.shape)) # 실제 이미지에 대한 라벨이 들어있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 번 이미지를 불러 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # matplotlib : 시각화 기능을 제공하는 라이브러리\n",
    "\n",
    "plt.imshow(x_train[0]) # 파이썬은 0번부터 수가 부여되므로 0이 첫번째!\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 네트위크 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 준비가 끝났습니다. 이제 가위바위보를 인식하는 딥러닝 네트워크를 설계해 볼까요?  \n",
    "텐서플로우 케라스(tf.keras)에서 Sequential API라는 방법을 사용할 겁니다.  \n",
    "Sequential API는 개발의 자유도는 많이 떨어지지만, 매우 간단하게 딥러닝 모델을 만들어낼 수 있는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_shape=(28, 28, 3)에서 1은 흑백, 3은 컬러 이미지(RGB)를 뜻합니다.  \n",
    "맨 아래 layers.Dense의 3은 클래스 수(가위, 바위, 보)를 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # 만든 딥러닝 네트워크 모델 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 설계가 되었다면, 이제 학습을 시켜볼까요?  \n",
    "아마도 직접 만든 데이터는 거의 비슷비슷할 것이기 때문에 accuracy가 꽤 높게 나올 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (300, 28, 28, 3)\n",
      "After Reshape - x_train_reshaped shape: (300, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "# print(\"Before Reshape - y_train_norm shape: {}\".format(y_train_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape(-1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "# y_train_reshaped=y_train_norm.reshape(-1, 28, 28, 3)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "# print(\"After Reshape - y_train_reshaped shape: {}\".format(y_train_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주석 해제시 NameError: name 'y_train_norm' is not defined 에러가 났습니다.  \n",
    "데이터 준비하기에서 y_train_norm 선언을 해보았지만 오류가 반복됩니다.\n",
    "아마 x_train_norm은 이미지인데 y_train_norm은 이미지가 아닌 학습시킨 이미지에 라벨번호를 부여하기 때문에 오류가 나는 것 같아 주석처리 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.4132\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0773 - accuracy: 0.6403\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0413 - accuracy: 0.9023\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9864 - accuracy: 0.7323\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9258 - accuracy: 0.7368\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8241 - accuracy: 0.7998\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.9452\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.9383\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.9302\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0360052750>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 그럼 300장의 가위바위보 이미지를 만들어 모두 학습에 사용했습니다.  \n",
    "그러므로 테스트 데이터가 없죠. 다른사람이 만든 새로운 데이터가 필요합니다. 저는 조원의 이미지 데이터 300장을 받아왔습니다.  \n",
    "그리고 그것을 테스트 데이터로 하여 test accuracy를 측정해보겠습니다.\n",
    "\n",
    "우선 테스트용 데이터인 **x_test, y_test**를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n",
      "Before Reshape - x_test _norm shape: (300, 28, 28, 3)\n",
      "After Reshape - x_test _reshaped shape: (300, 28, 28, 3)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2191 - accuracy: 0.4357\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9770 - accuracy: 0.5377\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9518 - accuracy: 0.5818\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8863 - accuracy: 0.6765\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8772 - accuracy: 0.6624\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8137 - accuracy: 0.6342\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.7456\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7716 - accuracy: 0.6710\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.8121\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7987\n",
      "10/10 - 0s - loss: 0.5900 - accuracy: 0.8167\n",
      "test_loss: 0.5899912118911743 \n",
      "test_accuracy: 0.8166666626930237\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/test_set\"\n",
    "(x_test, y_test)=load_data(image_dir_path, \"x_test\")\n",
    "\n",
    "x_test_norm = x_test/255.0   # 정규화\n",
    "y_test_norm = y_test\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "print(\"Before Reshape - x_test _norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "print(\"After Reshape - x_test _reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "print(\"-----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# compile : 모델을 학습시키기 위한 학습과정을 설정\n",
    "# metrics : accuracy로 설정 시 정확도를 알 수 있다.\n",
    "model.compile(optimizer='adam', # 최적화, optimizer='adam' : 거의 기본옵션처럼 쓰임\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_test_reshaped, y_test, epochs=10)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss)) # 손실율 계산\n",
    "print(\"test_accuracy: {}\".format(test_accuracy)) # 정확도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음..정확도가 생각보다 높게 나오네요. 그래도 좀 더 성능을 높이기 위해 다른 동기들의 데이터를 받아옵니다. 전처리 되지 않은게 있다면 1번과 마찬가지로 데이터전처리를 해주고 다시 측정해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 최종학습 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(train)의 이미지 개수는 14700입니다.\n",
      "x_train shape: (14700, 28, 28, 3)\n",
      "y_train shape: (14700,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, name): # 재선언, 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=14700   # 가위바위보 이미지 개수 총합변경\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32) # 임폴트한 numpy 사용\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*'): # *는 jpg, jpeg 모두 불러오기\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터({})의 이미지 개수는 {}입니다.\".format(name,idx))\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/train_set\"\n",
    "(x_train, y_train)=load_data(image_dir_path, \"train\")\n",
    "\n",
    "x_train_norm = x_train/255.0   # 255로 나눠서 정규화\n",
    "# y_train_norm = y_train # 이미지가 아닌 x_train_norm에 대한 라벨이 들어가 있으므로 주석처리\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape)) # 실제 이미지가 들어있음\n",
    "print(\"y_train shape: {}\".format(y_train.shape)) # 실제 이미지에 대한 라벨이 들어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10 # 횟수\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (14700, 28, 28, 3)\n",
      "After Reshape - x_train_reshaped shape: (14700, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "# print(\"Before Reshape - y_train_norm shape: {}\".format(y_train_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape(-1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "# y_train_reshaped=y_train_norm.reshape(-1, 28, 28, 3)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "# print(\"After Reshape - y_train_reshaped shape: {}\".format(y_train_reshaped.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4664\n",
      "Epoch 2/10\n",
      "460/460 [==============================] - 1s 2ms/step - loss: 0.6135 - accuracy: 0.7472\n",
      "Epoch 3/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.4107 - accuracy: 0.8443\n",
      "Epoch 4/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.2955 - accuracy: 0.8927\n",
      "Epoch 5/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.2150 - accuracy: 0.9282\n",
      "Epoch 6/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9394\n",
      "Epoch 7/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.1211 - accuracy: 0.9621\n",
      "Epoch 8/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9715\n",
      "Epoch 9/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.0823 - accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03501da590>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile : 모델을 학습시키기 위한 학습과정을 설정\n",
    "# metrics : accuracy로 설정 시 정확도를 알 수 있다.\n",
    "model.compile(optimizer='adam', # 최적화, 거의 기본옵션처럼 쓰임\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, name): # 재선언, 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합변경\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32) # 임폴트한 numpy 사용\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*'): # *는 jpg, jpeg 모두 불러오기\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터({})의 이미지 개수는 {}입니다.\".format(name,idx))\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n",
      "Before Reshape - x_test _norm shape: (300, 28, 28, 3)\n",
      "After Reshape - x_test _reshaped shape: (300, 28, 28, 3)\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9630 - accuracy: 0.8193\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1844 - accuracy: 0.9532\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9579\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "test_loss: 0.5899912118911743 \n",
      "test_accuracy: 0.8166666626930237\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/test_set_L\"\n",
    "\n",
    "(x_test, y_test)=load_data(image_dir_path, \"x_test\")\n",
    "x_test_norm = x_test/255.0   # 정규화\n",
    "y_test_norm = y_test\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "print(\"Before Reshape - x_test _norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "print(\"After Reshape - x_test _reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "\n",
    "# compile : 모델을 학습시키기 위한 학습과정을 설정\n",
    "# metrics : accuracy로 설정 시 정확도를 알 수 있다.\n",
    "model.compile(optimizer='adam', # 최적화, 거의 기본옵션처럼 쓰임\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_test_reshaped, y_test, epochs=10)\n",
    "\n",
    "print(\"test_loss: {} \".format(test_loss)) # 손실율 계산\n",
    "print(\"test_accuracy: {}\".format(test_accuracy)) # 정확도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 이미 사용했기 때문에 새로운 테스트 셋 파일을 만들어 테스트 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "test_loss: 0.0041976505890488625 \n",
      "test_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss)) # 손실률\n",
    "print(\"test_accuracy: {}\".format(test_accuracy)) # 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과는 사실 잘 모르겠지만 잘 나왔다(?) 로스값이 낮으니 맞겠죠...? 일단 시간이 없는 관계로 제출합니다. 퍼실님과 조원님들 덕분에 사진 정리도 했더니 정확도가 높게 나온 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노드 진행 할 때는 이해 했다고 생각했는데 과제 제출을 위해 직접 처음부터 해보니 아니었습니다.    \n",
    "첫번째 과제라 쉬운 걸로 주셨을텐데 퍼실님들 조언대로 잠시 시간을 가져보기도 하고 드러누워도 봤는데도 힘들어서 2주의 시간이었다면 2번의 주말이 있었을테니 좀 더 시간이 있어서 좋았을텐데 하는 생각이 들었습니다.  \n",
    "\n",
    "이미지를 28X28로 줄이면서 이걸 과연 얘가 구분해 낼 수 있을까? 했는데 생각보다 컴퓨터는 가르쳐주면 진짜 잘 하는데 내가 잘 못 알려줬던거구나 싶어서 슬펐습니다..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
