{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binding-programming",
   "metadata": {},
   "source": [
    "# 사람이 말하는 단어를 인공지능 모델로 구분해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-classic",
   "metadata": {},
   "source": [
    "2차원 Spectrogram 데이터를 입력받아 모델을 아래 제시된 단계와 같이 수행해 보겠습니다.  \n",
    "기본 버전과 Skip-connection 버전으로 나누어 각각 진행해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-mining",
   "metadata": {},
   "source": [
    "이제 오늘 만들어볼 음성인식 모델을 위한 학습데이터를 분석해 보겠습니다.  \n",
    "아래와 같이 환경을 구성한 후, 데이터 다운로드를 진행해 주세요.  \n",
    "**(주의 : 1.6GB의 대용량 데이터입니다. 다운로드에 시간이 오래걸릴 수 있으니 주의해 주세요.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-parcel",
   "metadata": {},
   "source": [
    "- mkdir -p ~/aiffel/speech_recognition/data  \n",
    "- mkdir -p ~/aiffel/speech_recognition/models  \n",
    "- wget https://aiffelstaticdev.blob.core.windows.net/dataset/speech_wav_8000.npz -P ~/aiffel/speech_recognition/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-ranking",
   "metadata": {},
   "source": [
    "### 이렇게 다운로드받은 waveform 형태의 데이터에 대해 좀더 자세한 정보를 정리해 봅시다.\n",
    "\n",
    "**Wave 데이터 형식 뜯어보기**  \n",
    "Audio 데이터는 이미지 데이터보다 낮은 차원의 데이터를 다룹니다. 1개의 wav 파일은 1차원으로 이루어진 시계열 데이터입니다. 실제로는 여러 소리 파형이 합쳐진 복합파라고 보아야 합니다.\n",
    "\n",
    "**간단한 단어 인식을 위한 훈련데이터셋**  \n",
    "짧은 단어의 라벨이 달려 있어, 음성들을 텍스트로 구분하는 모델 혹은 간단한 명령어를 구별하는 모델로도 학습이 가능합니다.\n",
    "\n",
    "**Bits per sample**  \n",
    "샘플 하나마다 소리의 세기를 몇 비트로 저장했는지를 나타냅니다.\n",
    "값이 커질 수록 세기를 정확하게 저장할 수 있습니다.\n",
    "예를 들어, Bits rate가 16 bits 라면, 소리의 세기를 \n",
    "2  16, 즉 65,536 단계로 표현할 수 있습니다.\n",
    "4 bits / 8 bits unsigned int / 16 bits int / 24 bits / 32 bits float 등의 자료형으로 표현됩니다.\n",
    "\n",
    "**Sampling frequency**  \n",
    "샘플링 주파수라는 단어입니다. 소리로부터 초당 샘플링한 횟수를 의미합니다.\n",
    "샘플링은 원래 신호를 다시 복원할 수 있는 나이퀴스트(Nyquist) 샘플링 룰에 따라서, 복원해야 할 신호 주파수의 2배 이상으로 샘플링 해야합니다.\n",
    "가청 주파수 20 ~ 24 kHz를 복원하기 위해 사용하며, 음원에서 많이 쓰이는 값은 44.1 kHz입니다.\n",
    "\n",
    "**Channel**  \n",
    "각 채널별로 샘플링된 데이터가 따로 저장되어 있습니다.\n",
    "2채널(Stereo) 음원을 재생하면 왼쪽(L)과 오른쪽(R) 스피커에 다른 값이 출력됩니다.\n",
    "1채널(Mono) 음원의 경우 왼쪽(L) 데이터만 있으며, 재생시엔 왼쪽(L)과 오른쪽(R) 스피커에 같은 값이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indie-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-seating",
   "metadata": {},
   "source": [
    "사용할 모듈들 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "angry-porcelain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "data_path = os.getenv(\"HOME\")+'/aiffel/speech_recognition/data/speech_wav_8000.npz'\n",
    "speech_data = np.load(data_path)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-davis",
   "metadata": {},
   "source": [
    "**데이터셋 살펴보기 : npz 파일로 이뤄진 데이터이며, 각각 데이터는 \"wav_vals\", \"label_vals\"로 저장되어있습니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hungarian-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave data shape :  (50620, 8000)\n",
      "Label data shape :  (50620, 1)\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "print(\"Wave data shape : \", speech_data[\"wav_vals\"].shape)\n",
    "print(\"Label data shape : \", speech_data[\"label_vals\"].shape)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-banana",
   "metadata": {},
   "source": [
    "- 데이터셋은 1초 길이의 오디오 음성데이터 **50620개**로 이뤄져 있습니다.  \n",
    "- 데이터셋은 캐글의 음성 인식 챌린지의 데이터입니다.  \n",
    "- 주어진 데이터의 원래 Sample rate는 16000이지만, 8000으로 re-sampling해 사용하겠습니다.  \n",
    "- 모두 1초의 길이를 가지는 오디오 음성데이터이여서 각각 **8000개**의 sample data를 가지고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-federation",
   "metadata": {},
   "source": [
    "위에서 설명한 데이터가 맞는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "necessary-rendering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand num :  13005\n",
      "Wave data shape :  (8000,)\n",
      "label :  ['right']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import IPython.display as ipd\n",
    "# import random\n",
    "\n",
    "# 데이터 선택 (랜덤하게 선택하고 있으니, 여러번 실행해 보세요)\n",
    "rand = random.randint(0, len(speech_data[\"wav_vals\"]))\n",
    "print(\"rand num : \", rand)\n",
    "\n",
    "sr = 8000 # 1초동안 재생되는 샘플의 갯수\n",
    "data = speech_data[\"wav_vals\"][rand]\n",
    "print(\"Wave data shape : \", data.shape)\n",
    "print(\"label : \", speech_data[\"label_vals\"][rand])\n",
    "\n",
    "ipd.Audio(data, rate=sr)  # 음성을 들을 수 있게 해주는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-impact",
   "metadata": {},
   "source": [
    "#### 쥬피터 환경에서는 ipd.Audio를 이용하여 오디오처럼 음성을 들을 수 있지만 깃허브에서는 작동이 안된다는 것을 알았습니다...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-citation",
   "metadata": {},
   "source": [
    "## 1. 데이터 처리와 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-process",
   "metadata": {},
   "source": [
    "**Label data 처리 : 학습을 위해서는 Text 데이터를 학습가능한 형태로 만들어줘야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-intelligence",
   "metadata": {},
   "source": [
    "아래는 구분해야할 label 목록입니다.\n",
    "\n",
    "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go' ]\n",
    "\n",
    "이외 데이터들은 'unknown', 'silence'로 분류되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "graphic-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL :  ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence']\n",
      "Indexed LABEL :  {'yes': 0, 'no': 1, 'up': 2, 'down': 3, 'left': 4, 'right': 5, 'on': 6, 'off': 7, 'stop': 8, 'go': 9, 'unknown': 10, 'silence': 11}\n"
     ]
    }
   ],
   "source": [
    "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "label_value = target_list\n",
    "label_value.append('unknown')\n",
    "label_value.append('silence')\n",
    "\n",
    "print('LABEL : ', label_value)\n",
    "\n",
    "new_label_value = dict()\n",
    "for i, l in enumerate(label_value):\n",
    "    new_label_value[l] = i\n",
    "label_value = new_label_value\n",
    "\n",
    "print('Indexed LABEL : ', new_label_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-history",
   "metadata": {},
   "source": [
    "Text로 이루어진 라벨 데이터를 학습에 사용하기 위해서 index 형태로 바꿔주는 작업을 하였습니다.\n",
    "\n",
    "int로 이뤄진 index 작업을 통해서 Label data를 더 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efficient-ordinary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  3, ..., 11, 11, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "for v in speech_data[\"label_vals\"]:  # label_val : 타겟값\n",
    "    temp.append(label_value[v[0]])\n",
    "label_data = np.array(temp)\n",
    "\n",
    "label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-individual",
   "metadata": {},
   "source": [
    "**학습을 위한 데이터 분리 : sklearn의 train_test_split 함수를 이용해 train data와 test data를 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lyric-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1108767e-03 -2.6847699e-03 -2.7988575e-04 ...  1.3695330e-03\n",
      "  -2.3802987e-03  2.0389911e-03]\n",
      " [-1.5100831e-04 -4.5792345e-04 -5.6165853e-04 ...  6.0415751e-04\n",
      "   6.5859995e-04  5.1307929e-04]\n",
      " [ 4.0693092e-03  6.3273199e-03  2.1763751e-03 ...  3.6290758e-03\n",
      "   3.4729466e-03 -2.5351008e-04]\n",
      " ...\n",
      " [-1.3508837e-04  1.9908934e-05  1.3992477e-04 ... -1.1790385e-05\n",
      "   3.8305709e-05 -7.3200790e-05]\n",
      " [ 5.6373228e-05  3.4249533e-05  4.8491231e-05 ... -1.7500951e-04\n",
      "  -1.7405850e-04 -1.8586969e-04]\n",
      " [-2.2722787e-04 -2.1830836e-04 -3.6256426e-04 ... -3.2663671e-04\n",
      "  -5.2177685e-04 -1.0008253e-03]]\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "sr = 8000\n",
    "train_wav, test_wav, train_label, test_label = train_test_split(speech_data[\"wav_vals\"], \n",
    "                                                                label_data, \n",
    "                                                                test_size=0.2,  # test_size의 인자를 조절해주면, 설정해 준 값만큼 Test dataset의 비율을 조정할 수 있음!\n",
    "                                                                shuffle=True)\n",
    "print(train_wav)\n",
    "\n",
    "train_wav = train_wav.reshape([-1, sr, 1]) # add channel for CNN\n",
    "test_wav = test_wav.reshape([-1, sr, 1])\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thermal-grass",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'spectograms' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-381a12edcfba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspectograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_wav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrogramize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_wav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_wav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrogramize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_wav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-381a12edcfba>\u001b[0m in \u001b[0;36mspectrogramize\u001b[0;34m(speech_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspeech_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mspectograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav2spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mspectograms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectograms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'spectograms' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def spectrogramize(speech_data):\n",
    "    spectrograms = []\n",
    "    \n",
    "    for i in speech_data:\n",
    "        spectograms.append(wav2spec(i))\n",
    "        \n",
    "    spectograms = np.array(spectograms)\n",
    "    return spectograms\n",
    "\n",
    "train_wav = spectrogramize(train_wav) \n",
    "test_wav = spectrogramize(test_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-auction",
   "metadata": {},
   "source": [
    "나눠진 데이터셋을 확인해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train data : \", train_wav.shape)\n",
    "print(\"train labels : \", train_label.shape)\n",
    "print(\"test data : \", test_wav.shape)\n",
    "print(\"test labels : \", test_label.shape)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-superior",
   "metadata": {},
   "source": [
    "## 2. 학습을 위한 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-millennium",
   "metadata": {},
   "source": [
    "모델 체크포인트 저장을 위한 체크포인트의 경로를 설정해줍니다.  \n",
    "후에 모델 체크포인트 Callback 함수를 설정하거나, 모델을 불러올때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-sierra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 10\n",
    "\n",
    "# checkpoint, callback(=call-after function) 함수 추가\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/speech_recognition/models/wav'\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-paradise",
   "metadata": {},
   "source": [
    "- **checkpoint 함수** : 모델 가중치를 저장하는 함수  \n",
    "- **callback(=call-after function) 함수** : 콜백을 넘겨받는 코드는 이 콜백을 필요에 따라 즉시 실행할 수도 있고, 아니면 나중에 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-bracket",
   "metadata": {},
   "source": [
    "## 3. 데이터셋 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-block",
   "metadata": {},
   "source": [
    "map 함수는 dataset이 데이터를 불러올때마다 동작시킬 데이터 전처리 함수를 매핑해 주는 역할을 합니다. 첫번째 map 함수는 from_tensor_slice 에 입력한 튜플 형태로 데이터를 받으며 return 값으로 어떤 데이터를 반환할지 결정합니다.\n",
    "map 함수는 중첩해서 사용이 가능합니다.\n",
    "\n",
    "아래와 같이, map 함수에 넘겨줄 데이터 전처리 함수를 작성해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(wav, label):\n",
    "    label = tf.one_hot(label, depth=12)\n",
    "    return wav, label\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-capitol",
   "metadata": {},
   "source": [
    "tf.data.Dataset 함수를 이용해서 데이터셋을 구성하겠습니다.  \n",
    "Tensorflow에 포함된 이 데이터셋 관리 패키지는 데이터셋 전처리, 배치처리 등을 쉽게 할 수 있도록 해 줍니다. 자주 사용하게 되니 사용법을 잘 익혀 둡시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_wav, train_label))  # return 받길 원하는 데이터를 튜플 (data, label) 형태로 넣어서 사용할 수 있습니다.\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_wav, test_label))  # return 받길 원하는 데이터를 튜플 (data, label) 형태로 넣어서 사용할 수 있습니다.\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)  # dataset에서 제공하는 튜플 형태의 데이터를 얼마나 가져올지 결정하는 함수\n",
    "print(test_dataset)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-alert",
   "metadata": {},
   "source": [
    "## 4. 2차원 Spectrogram 데이터를 처리하는 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-tutorial",
   "metadata": {},
   "source": [
    "- 주의 : waveform을 spectrogram으로 변환하기 위해 추가로 사용하는 메모리 때문에 이후 메모리 부족 현상을 겪게 될수도 있습니다.\n",
    "- tf.data.Dataset이 생성된 이후, 아래 예시와 같이 wav 데이터나 spectrogram 데이터를 담아둔 메모리 버퍼를 비워 주면 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del speech_data  \n",
    "# del spec_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-fifth",
   "metadata": {},
   "source": [
    "**Spectrogram이란?**\n",
    "\n",
    "wav 데이터를 해석하는 방법 중 하나로, 일정 시간동안 wav 데이터 안의 다양한 주파수들이 얼마나 포함되어 있는 지를 보여줍니다.  \n",
    "X축은 시간, Y축은 주파수를 나타내며, 해당 시간/주파수에서의 음파 강도에 따라 밝은색으로 표현됩니다.\n",
    "wav 데이터가 단위 시간만큼 Short Time Fourier Transform을 진행해 매 순간의 주파수 데이터들을 얻어서 Spectrogram을 완성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-serbia",
   "metadata": {},
   "source": [
    "먼저 파이썬에서 제공하는 FFT 관련 라이브러리인 librosa를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa : spectogram을 만들어주는 librosa 라이브러리\n",
    "\n",
    "def wav2spec(wav, fft_size=258): # spectrogram shape을 맞추기위해서 size 변형\n",
    "    D = np.abs(librosa.stft(wav, n_fft=fft_size))\n",
    "    return D\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 뽑았던 sample data\n",
    "spec = wav2spec(data)\n",
    "print(\"Waveform shape : \",data.shape)\n",
    "print(\"Spectrogram shape : \",spec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-fancy",
   "metadata": {},
   "source": [
    "어떻습니까? 1차원의 Waveform 데이터가 2차원의 Spectrogram 데이터로 변환되었습니다.\n",
    "\n",
    "그렇다면 방금 변환된 Spectrogram을 출력해보겠습니다.\n",
    "\n",
    "만약에, 우리가 Waveform 데이터 대신 이 Spectrogram 포맷으로 모든 음성 데이터를 변환한 후 음성인식 모델을 학습시킨다면, 과연 Waveform과 비교했을 때 더 나은 성능을 기대할 수 있을까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-floor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(spec, ref=np.max), x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.xticks(range(0, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-vitamin",
   "metadata": {},
   "source": [
    "## 5. 학습 후, 학습이 어떻게 진행됐는지 그래프로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-collar",
   "metadata": {},
   "source": [
    "###### loss, accuracy를 그래프로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav = train_wav.reshape(-1, sr, 126, 1)\n",
    "#위의 batch된 데이터들과 맞춰준다\n",
    "#-1옵션은 size를 기반으로 row의 개수를 선정한다\n",
    "test_wav = test_wav.reshape(-1, sr, 126, 1)\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "input_tensor = layers.Input(shape=(sr, 126, 1))\n",
    "\n",
    "# 2차원 Spectrogram 데이터의 시간축 방향으로 Conv1D layer를 적용, 혹은 Conv2D layer를 적용 가능\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "skip_1 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(skip_1)\n",
    "x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_1], -1)\n",
    "skip_2 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(skip_2)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_2], -1)\n",
    "skip_3 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(skip_3)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, (3,3), padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_3], -1)\n",
    "# Batchnorm, Dropout, Dense layer등을 이용\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_wav = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "# 12개의 단어 class를 구분하는 loss를 사용하고 Adam optimizer를 사용\n",
    "model_wav.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-costa",
   "metadata": {},
   "source": [
    "ValueError: cannot reshape array of size 323968000 into shape (8000,126,1) 에러가 나서 조원들과 의견을 나눠보았는데 전처리단계에서 2차원 Spectrogram로 변환할 때 데이터셋을 나눈뒤 처리하면 오류가 나지 않는다는 결론을 얻었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30분 내외 소요\n",
    "\n",
    "history_wav_skip = model_wav_skip.fit(train_dataset, epochs=max_epochs,\n",
    "                    steps_per_epoch=len(train_wav) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_wav) // batch_size,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-relevance",
   "metadata": {},
   "source": [
    "## 6. Test dataset을 이용해서 모델의 성능을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_wav_skip.history['accuracy']\n",
    "val_acc = history_wav_skip.history['val_accuracy']\n",
    "\n",
    "loss=history_wav_skip.history['loss']\n",
    "val_loss=history_wav_skip.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능평가\n",
    "\n",
    "model_wav_skip.load_weights(checkpoint_dir)\n",
    "results = model_wav_skip.evaluate(test_dataset)\n",
    "\n",
    "print(\"loss value: {:.3f}\".format(results[0]))  # loss\n",
    "print(\"accuracy value: {:.4f}%\".format(results[1]*100))  # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-threat",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-affair",
   "metadata": {},
   "source": [
    "프로젝트 3과 4를 날려먹은 만큼 이번 프로젝트는 꼭 제출하고 싶었는데요, 막막한건 여전했습니다. ㅠㅠㅠ\n",
    "날잡고 다시 한번 개념을 정독해야겠습니다.\n",
    "저를 다독여가며 챙겨운 우리 조원들에게 고마움이 큽니다.♥\n",
    "더 열심히 배워나가서 저도 도움이 되고 싶네요:D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
