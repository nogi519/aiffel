{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "higher-amsterdam",
   "metadata": {},
   "source": [
    "# <center><span style=\"color:#2C786C\">프로젝트 : GQA 모델 활용하기</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-swing",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-reset",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-johnston",
   "metadata": {},
   "source": [
    "## <span style=\"color:#F7B400\">목표</span>\n",
    "> **<span style=\"color:#2C786C\">VQA를 위한 Pretrained model 중 대표적인 모델인 LXMERT 구현체를 통해 Multimodal NLP task의 구성 특징을 파악해 본다.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-marketing",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-constant",
   "metadata": {},
   "source": [
    "## <span style=\"color:#F7B400\">순서</span>\n",
    "> **<span style=\"color:#2C786C\">Step 1. 다른 이미지 테스트해 보기</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 2. GQA 데이터셋 버전 모델 테스트해 보기\n",
    "</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 3.  내가 선택한 이미지로 VQA/GQA 버전 비교해 보기</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 4. 루브릭 평가</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 5. 회고</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-reality",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-buffer",
   "metadata": {},
   "source": [
    "### <span style=\"color:#926DD6\">참고</span>\n",
    ">* []()\n",
    ">* []()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-prophet",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-partnership",
   "metadata": {},
   "source": [
    "### <span style=\"color:#926DD6\">개념</span>\n",
    ">* \n",
    ">>*\n",
    ">>*\n",
    "\n",
    ">* \n",
    ">>*\n",
    ">>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-allowance",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-benchmark",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-scheme",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#45C5CC\">✓ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-river",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-analysis",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 1. 다른 이미지 테스트해 보기</span>\n",
    "---\n",
    "앞서 실습해 본 LXMERT 모델 활용법을 다른 이미지를 통해서도 한번 시도하고 결과를 확인해 봅시다.\n",
    "\n",
    "![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/COCO_test2014_000000262567.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-victim",
   "metadata": {},
   "source": [
    "    URL = \"https://vqa.cloudcv.org/media/test2014/COCO_test2014_000000262567.jpg\"\n",
    "\n",
    "    test_questions_for_url2 = [\n",
    "        \"Where is the cat?\",\n",
    "        \"What is near the disk?\",\n",
    "        \"What is the color of the table?\",\n",
    "        \"What is the color of the cat?\",\n",
    "        \"What is the shape of the monitor?\",\n",
    "        \"What is the color of the keyboard?\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-consequence",
   "metadata": {},
   "source": [
    "* F-RCNN 모델을 이용해 새로운 URL로 주어진 이미지에 대해 bounding box를 그려 봅시다.\n",
    "* **`test_questions_for_url2`**에 주어진 질문에 대한 답을 찾아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-brunei",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-syndicate",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-italy",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 2. GQA 데이터셋 버전 모델 테스트해 보기</span>\n",
    "---\n",
    "이전 노드에서 소개했던 VQA를 위한 다양한 데이터셋 중에 GQA라는 것이 있었습니다. 이 데이터셋은 scene graph라는 것을 활용해서 object간 관계를 더욱 명확하게 학습할 수 있도록 한 것입니다.\n",
    "\n",
    "지금까지 사용했던 모델은 VQA2 데이터셋을 활용해 학습시킨 모델이었습니다. Huggingface에서는 동일한 모델 구조를 활용해 GQA로 학습시킨 모델을 함께 제공하고 있습니다. 아래 정보를 활용해 위 STEP 1. 에서 테스트했던 이미지에 대해 동일하게 테스트해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-affiliation",
   "metadata": {},
   "source": [
    "    GQA_URL = \"https://raw.githubusercontent.com/airsplay/lxmert/master/data/gqa/trainval_label2ans.json\"\n",
    "\n",
    "    lxmert_gqa = LxmertForQuestionAnswering.from_pretrained(\"unc-nlp/lxmert-gqa-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-steel",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-turtle",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 3. 내가 선택한 이미지로 VQA/GQA 버전 비교해 보기</span>\n",
    "---\n",
    "* 이번에는 여러분들이 임의로 이미지를 하나 골라 봅시다.\n",
    "* 이미지에 대해 3~5가지 정도 영어로 질문을 작성해 봅시다.\n",
    "* STEP 1, 2에서 수행했던 내용을 본인이 고른 이미지에 대해 동일하게 수행하고, 결과를 비교해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-animation",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-johnson",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-baking",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 4. 루브릭 평가</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-prize",
   "metadata": {},
   "source": [
    "|평가문항|상세기준|\n",
    "|-------|--------|\n",
    "|1. LXMERT 모델을 활용해 새로운 이미지에 대한 VQA 작업을 진행하였다.|이미지 bounding box 시각화 및 question에 대한 answer 출력이 정상적으로 진행되었다.|\n",
    "|2. GQA 버전의 LXMERT 모델을 활용해 VQA 작업을 진행하였다.|GQA 버전 모델을 활용하여 question에 대한 answer 출력이 정상적으로 진행되었다.|\n",
    "|3. VQA, GQA 버전의 성능을 체계적으로 비교분석하였다.|자신이 선택한 다양한 이미지에 대해 두 모델의 답안이 어떻게 달라지는지 비교분석 결과를 제출하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-professor",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-companion",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 5. 회고</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-banks",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
