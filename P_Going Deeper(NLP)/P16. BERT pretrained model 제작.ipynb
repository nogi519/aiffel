{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regular-journey",
   "metadata": {},
   "source": [
    "# <center><span style=\"color:#2C786C\">프로젝트 : mini BERT 만들기</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-thesaurus",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-relationship",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-actor",
   "metadata": {},
   "source": [
    "## <span style=\"color:#F7B400\">목표</span>\n",
    "> **<span style=\"color:#2C786C\">가장 대표적인 pretrained ㅣlanguage model인 BERT의 pretrain 전과정을 진행해 보면서 BERT의 핵심원리를 깊이 이해해 본다.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-package",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-buyer",
   "metadata": {},
   "source": [
    "## <span style=\"color:#F7B400\">순서</span>\n",
    "> **<span style=\"color:#2C786C\">Step 1. Tokenizer 준비</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 2. 데이터 전처리 (1) MASK 생성</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 3. 데이터 전처리 (2) NSP pair 생성</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 4. 데이터 전처리 (3) 데이터셋 완성</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 5. BERT 모델 구현</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 6. pretrain 진행</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 7. 프로젝트 결과</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 8. 루브릭 평가</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 9. 회고</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-organization",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-parish",
   "metadata": {},
   "source": [
    "### <span style=\"color:#926DD6\">참고</span>\n",
    ">* []()\n",
    ">* []()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-litigation",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-vienna",
   "metadata": {},
   "source": [
    "### <span style=\"color:#926DD6\">개념</span>\n",
    ">* \n",
    ">>*\n",
    ">>*\n",
    "\n",
    ">* \n",
    ">>*\n",
    ">>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-flash",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-beaver",
   "metadata": {},
   "source": [
    "지금까지 BERT 모델을 pretrain하는 험난한 여정을 잘 따라오셨나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-courtesy",
   "metadata": {},
   "source": [
    "이번 프로젝트의 과제는 간단합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-worth",
   "metadata": {},
   "source": [
    "vocab size를 8000으로 줄이고, 전체 파라미터 사이즈가 1M 정도가 되는 아주 작은 mini BERT 모델을 만들어 10Epoch까지 학습시킨 모델을 만들어 보는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-bangkok",
   "metadata": {},
   "source": [
    "그래서 학습 진행 결과를 시각화하여 제출해 주세요. 수고 많으셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-triumph",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-creature",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#45C5CC\">✓ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-motion",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-airline",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 1. Tokenizer 준비</span> <span style=\"color:#D43838\">(매우 중요!!!)</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-submission",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-twins",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-director",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-queens",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-saskatchewan",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 2. 데이터 전처리 (1) MASK 생성</span>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-findings",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-islam",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 3. 데이터 전처리 (2) NSP pair 생성</span>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-intro",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-pilot",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 4. 데이터 전처리 (3) 데이터셋 완성</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-blade",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 5. BERT 모델 구현</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-programmer",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 6. pretrain 진행</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-diagram",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 7. 프로젝트 결과</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-nicholas",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-washington",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 8. 루브릭 평가</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-picnic",
   "metadata": {},
   "source": [
    "|평가문항|상세기준|\n",
    "|-------|--------|\n",
    "|1. 한글 코퍼스를 가공하여 BERT pretrain용 데이터셋을 잘 생성하였다.|MLM, NSP task의 특징이 잘 반영된 pretrain용 데이터셋 생성과정이 체계적으로 진행되었다.|\n",
    "|2. 구현한 BERT 모델의 학습이 안정적으로 진행됨을 확인하였다.|학습진행 과정 중에 MLM, NSP loss의 안정적인 감소가 확인되었다.|\n",
    "|3. 1M짜리 mini BERT 모델의 제작과 학습이 정상적으로 진행되었다.|학습된 모델 및 학습과정의 시각화 내역이 제출되었다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-healing",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-biodiversity",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 9. 회고</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-induction",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
