{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "refined-humanitarian",
   "metadata": {},
   "source": [
    "# <center><span style=\"color:#2C786C\">프로젝트 : Vocabulary Size를 변경해서 시도해보기</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-ratio",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-albania",
   "metadata": {},
   "source": [
    "지금까지는 모델을 변경하고, 모델을 조합해서 성능을 올리는 일에 힘썼습니다. 그런데 어쩌면 성능을 높이는 방법은 단순히 모델을 조정하는 일이 한정되지 않을 수 있습니다. 데이터의 전처리는 모델의 성능에 영향을 직접적으로 줍니다. 특히나 Bag of Words를 기반으로 하는 DTM이나 TF-IDF의 경우, 사용하는 단어의 수를 어떻게 결정하느냐에 따라서 성능에 영향을 줄 수 있겠죠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-harbor",
   "metadata": {},
   "source": [
    "중요도가 낮은 단어들까지 포함해서 너무 많은 단어를 사용하는 경우에도 성능이 저하될 수 있고, 반대로 너무 적은 단어들을 사용해도 성능이 저하될 수 있습니다. 그리고 이렇게 변화된 단어의 수는 또 어떤 모델을 사용하느냐에 따라 유리할 수도, 불리할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-express",
   "metadata": {},
   "source": [
    "단어의 수에 따라서 모델의 성능이 어떻게 변하는지 테스트해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-annotation",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-tucson",
   "metadata": {},
   "source": [
    "앞서 **`num_words`**로 사용할 단어의 수를 조정할 수 있다는 것을 배웠습니다. 빈도수가 많은 순서대로 나열했을 때, **`num_words`**의 인자로 준 정숫값만큼의 단어를 사용하고 나머지 단어는 전부 **`<unk>`**로 처리하는 원리였었죠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-disabled",
   "metadata": {},
   "source": [
    "아래의 두 가지 경우에 대해서 지금까지 사용했던 모델들의 정확도를 직접 확인해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-antarctica",
   "metadata": {},
   "source": [
    "## <span style=\"color:#F7B400\">순서</span>\n",
    "> **<span style=\"color:#2C786C\">Step 1. 모든 단어 사용</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 2. 빈도수 상위 5,000개의 단어만 사용</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 3. 직접 단어 갯수를 설정해서 사용</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 4. 딥러닝 모델과 비교해 보기</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 5. 정리</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 6. 루브릭 평가</span>**<br>\n",
    "**<span style=\"color:#2C786C\">Step 7. 회고</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-rehabilitation",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-caribbean",
   "metadata": {},
   "source": [
    "### <span style=\"color:#926DD6\">참고</span>\n",
    ">* [EXPLORATION_DJ 4. 영화리뷰 텍스트 감성분석하기]()\n",
    ">* [딥 러닝을 이용한 자연어 처리 입문(wikidocs) : 네이버 영화 리뷰 감성 분류하기(Naver Movie Review Sentiment Analysis)](https://wikidocs.net/44249)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-teddy",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-skirt",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 1. 모든 단어 사용</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-single",
   "metadata": {},
   "source": [
    "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-warning",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-fleet",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 2. 빈도수 상위 5,000개의 단어만 사용</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-distributor",
   "metadata": {},
   "source": [
    "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-qatar",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-topic",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 3. 직접 단어 갯수를 설정해서 사용</span>\n",
    "---\n",
    "위 단계에서 5000으로 제시된 **`num_words`**를 다양하게 바꾸어 가며 성능을 확인해보세요. 변화된 단어 수에 따른 모델의 성능을 연구해 보세요. **최소 3가지 경우 이상을 실험**해 보기를 권합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-issue",
   "metadata": {},
   "source": [
    "> ***사용할 모델***<br>\n",
    "> *나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blank-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "driven-driving",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "(x_train_2, y_train_2), (x_test_2, y_test_2) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "(x_train_3, y_train_3), (x_test_3, y_test_3) = reuters.load_data(num_words=2500, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medium-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acoustic-survivor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "velvet-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스의 수 : 46\n"
     ]
    }
   ],
   "source": [
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fallen-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loaded-civilization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(12,5)\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interesting-level",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "phantom-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stable-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "three-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extreme-defensive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "print(index_to_word[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sublime-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "black-textbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "academic-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the transaction is expected to be completed\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([index_to_word[index] for index in [4, 587, 23, 133,6, 30, 515]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "micro-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vanilla-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train_2)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train_2[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train_2 = decoded\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test_2[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test_2 = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "infinite-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train_2)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train_3[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train_3 = decoded\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test_3[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test_3 = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hidden-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "offshore-international",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "peaceful-design",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sexual-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(train, test):\n",
    "    dtmvector = CountVectorizer()\n",
    "    train_dtm = dtmvector.fit_transform(train)\n",
    "    \n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    tfidfv = tfidf_transformer.fit_transform(train_dtm)\n",
    "    \n",
    "    test_dtm = dtmvector.transform(test) #테스트 데이터를 DTM으로 변환\n",
    "    tfidfv_test = tfidf_transformer.transform(test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "    return tfidfv, tfidfv_test\n",
    "\n",
    "# 나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅\n",
    "def pipeline(x_train, y_train, x_test, y_test):\n",
    "    # tfidf\n",
    "    (tfidfv, tfidfv_test) = tfidf(x_train,x_test)\n",
    "    \n",
    "    # multi_NB\n",
    "    print('multi_NB')\n",
    "    mod = MultinomialNB()\n",
    "    mod.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, mod.predict(tfidfv_test)))\n",
    "    \n",
    "    # CN\n",
    "    print('CNB')\n",
    "    cb = ComplementNB()\n",
    "    cb.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, cb.predict(tfidfv_test)))\n",
    "\n",
    "    # logistic regression\n",
    "    print('logistic')\n",
    "    lr = LogisticRegression(C=10000, penalty='l2')\n",
    "    lr.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, lr.predict(tfidfv_test)))\n",
    "    \n",
    "    # SVM\n",
    "    print('SVM')\n",
    "    lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "    lsvc.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, lsvc.predict(tfidfv_test)))\n",
    "\n",
    "    # DT\n",
    "    print('DT')\n",
    "    tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "    tree.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, tree.predict(tfidfv_test)))\n",
    "\n",
    "    # RF\n",
    "    print('RF')\n",
    "    forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "    forest.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, forest.predict(tfidfv_test)))\n",
    "    \n",
    "    # GRBT\n",
    "    print('GRBT')\n",
    "    grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "    grbt.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, grbt.predict(tfidfv_test)))\n",
    "\n",
    "    # voting\n",
    "    print('voting')\n",
    "    voting = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "    ], voting='soft', n_jobs=-1)\n",
    "    voting.fit(tfidfv, y_train)\n",
    "    print(classification_report(y_test, voting.predict(tfidfv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "wireless-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.62      0.69      0.65       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.81      0.90      0.85       813\n",
      "           4       0.51      0.96      0.67       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.08      0.15        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.66      0.63      0.64        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       1.00      0.03      0.05        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.69      0.56      0.61        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.60      0.78      0.68       133\n",
      "          20       1.00      0.04      0.08        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       1.00      0.03      0.06        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.66      2246\n",
      "   macro avg       0.17      0.10      0.10      2246\n",
      "weighted avg       0.59      0.66      0.58      2246\n",
      "\n",
      "CNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.64      0.88      0.74       105\n",
      "           2       0.91      0.50      0.65        20\n",
      "           3       0.91      0.89      0.90       813\n",
      "           4       0.75      0.92      0.83       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.50      0.13      0.21        38\n",
      "           9       0.82      0.92      0.87        25\n",
      "          10       0.96      0.80      0.87        30\n",
      "          11       0.55      0.73      0.63        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.58      0.59      0.59        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.50      0.11      0.18         9\n",
      "          16       0.67      0.79      0.73        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.55      0.60      0.57        20\n",
      "          19       0.55      0.80      0.65       133\n",
      "          20       0.75      0.30      0.43        70\n",
      "          21       0.74      0.63      0.68        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.75      0.50      0.60        12\n",
      "          24       0.50      0.11      0.17        19\n",
      "          25       0.85      0.74      0.79        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.25      0.10      0.14        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       1.00      0.31      0.47        13\n",
      "          32       1.00      0.70      0.82        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      0.71      0.83         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       1.00      0.20      0.33         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       1.00      0.17      0.29         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.44      0.48      2246\n",
      "weighted avg       0.75      0.77      0.75      2246\n",
      "\n",
      "logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.75      0.78      0.76       105\n",
      "           2       0.74      0.85      0.79        20\n",
      "           3       0.92      0.93      0.93       813\n",
      "           4       0.81      0.87      0.84       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.68      0.71      0.69        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       0.64      0.73      0.68        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.59      0.59      0.59        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.67      0.44      0.53         9\n",
      "          16       0.68      0.75      0.71        99\n",
      "          17       0.75      0.75      0.75        12\n",
      "          18       0.86      0.60      0.71        20\n",
      "          19       0.68      0.68      0.68       133\n",
      "          20       0.62      0.49      0.54        70\n",
      "          21       0.63      0.81      0.71        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.64      0.58      0.61        12\n",
      "          24       0.62      0.53      0.57        19\n",
      "          25       0.95      0.68      0.79        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.57      0.40      0.47        10\n",
      "          29       0.57      1.00      0.73         4\n",
      "          30       0.88      0.58      0.70        12\n",
      "          31       0.78      0.54      0.64        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.36      0.36      0.36        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.75      0.30      0.43        10\n",
      "          41       0.83      0.62      0.71         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.75      1.00      0.86         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.71      0.62      0.64      2246\n",
      "weighted avg       0.80      0.81      0.80      2246\n",
      "\n",
      "SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.68      0.72      0.70       105\n",
      "           2       0.78      0.70      0.74        20\n",
      "           3       0.90      0.92      0.91       813\n",
      "           4       0.80      0.84      0.82       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.59      0.71      0.64        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.89      0.83      0.86        30\n",
      "          11       0.62      0.70      0.66        83\n",
      "          12       0.40      0.31      0.35        13\n",
      "          13       0.60      0.57      0.58        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.43      0.33      0.38         9\n",
      "          16       0.67      0.73      0.70        99\n",
      "          17       0.80      0.33      0.47        12\n",
      "          18       0.81      0.65      0.72        20\n",
      "          19       0.66      0.67      0.67       133\n",
      "          20       0.51      0.46      0.48        70\n",
      "          21       0.59      0.81      0.69        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.43      0.25      0.32        12\n",
      "          24       0.47      0.47      0.47        19\n",
      "          25       0.85      0.74      0.79        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.50      0.40      0.44        10\n",
      "          29       0.33      0.50      0.40         4\n",
      "          30       0.62      0.42      0.50        12\n",
      "          31       0.75      0.46      0.57        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.50      0.43      0.46         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.56      0.45      0.50        11\n",
      "          37       0.50      1.00      0.67         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.50      0.20      0.29         5\n",
      "          40       0.50      0.30      0.37        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.86      1.00      0.92         6\n",
      "          44       0.80      0.80      0.80         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.78      2246\n",
      "   macro avg       0.67      0.58      0.60      2246\n",
      "weighted avg       0.78      0.78      0.78      2246\n",
      "\n",
      "DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.72      0.42      0.53       105\n",
      "           2       0.62      0.50      0.56        20\n",
      "           3       0.93      0.83      0.88       813\n",
      "           4       0.40      0.90      0.56       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.90      0.64      0.75        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.88      0.88      0.88        25\n",
      "          10       0.85      0.77      0.81        30\n",
      "          11       0.64      0.51      0.56        83\n",
      "          12       0.14      0.08      0.10        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.59      0.84      0.69        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.62      0.29      0.39       133\n",
      "          20       0.27      0.06      0.09        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.67      0.11      0.18        19\n",
      "          25       0.86      0.19      0.32        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.50      0.10      0.17        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.23      0.18      0.18      2246\n",
      "weighted avg       0.61      0.62      0.58      2246\n",
      "\n",
      "RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.33      0.27        12\n",
      "           1       0.45      0.77      0.57       105\n",
      "           2       0.30      0.30      0.30        20\n",
      "           3       0.82      0.90      0.86       813\n",
      "           4       0.61      0.83      0.70       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.67      0.43      0.52        14\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.67      0.53      0.59        38\n",
      "           9       0.70      0.28      0.40        25\n",
      "          10       0.75      0.30      0.43        30\n",
      "          11       0.55      0.59      0.57        83\n",
      "          12       0.40      0.15      0.22        13\n",
      "          13       0.37      0.19      0.25        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.59      0.59      0.59        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.50      0.25      0.33        20\n",
      "          19       0.69      0.54      0.61       133\n",
      "          20       0.57      0.29      0.38        70\n",
      "          21       0.67      0.30      0.41        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.67      0.11      0.18        19\n",
      "          25       1.00      0.32      0.49        31\n",
      "          26       1.00      0.25      0.40         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.50      0.08      0.14        12\n",
      "          31       0.67      0.15      0.25        13\n",
      "          32       0.67      0.20      0.31        10\n",
      "          33       1.00      0.60      0.75         5\n",
      "          34       0.50      0.14      0.22         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.33      0.09      0.14        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.67      0.33      0.44         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.46      0.27      0.31      2246\n",
      "weighted avg       0.66      0.67      0.64      2246\n",
      "\n",
      "GRBT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        12\n",
      "           1       0.77      0.68      0.72       105\n",
      "           2       0.78      0.70      0.74        20\n",
      "           3       0.88      0.91      0.89       813\n",
      "           4       0.76      0.83      0.79       474\n",
      "           5       0.50      0.20      0.29         5\n",
      "           6       0.80      0.86      0.83        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.64      0.66      0.65        38\n",
      "           9       0.74      0.80      0.77        25\n",
      "          10       0.90      0.87      0.88        30\n",
      "          11       0.63      0.64      0.63        83\n",
      "          12       0.33      0.46      0.39        13\n",
      "          13       0.62      0.49      0.55        37\n",
      "          14       0.14      0.50      0.22         2\n",
      "          15       0.38      0.33      0.35         9\n",
      "          16       0.73      0.73      0.73        99\n",
      "          17       0.27      0.25      0.26        12\n",
      "          18       0.59      0.50      0.54        20\n",
      "          19       0.69      0.65      0.67       133\n",
      "          20       0.67      0.46      0.54        70\n",
      "          21       0.70      0.78      0.74        27\n",
      "          22       1.00      0.14      0.25         7\n",
      "          23       0.54      0.58      0.56        12\n",
      "          24       0.61      0.58      0.59        19\n",
      "          25       0.89      0.55      0.68        31\n",
      "          26       0.71      0.62      0.67         8\n",
      "          27       0.50      0.50      0.50         4\n",
      "          28       0.38      0.30      0.33        10\n",
      "          29       0.23      0.75      0.35         4\n",
      "          30       0.45      0.42      0.43        12\n",
      "          31       0.62      0.38      0.48        13\n",
      "          32       1.00      0.90      0.95        10\n",
      "          33       0.75      0.60      0.67         5\n",
      "          34       0.67      0.29      0.40         7\n",
      "          35       0.80      0.67      0.73         6\n",
      "          36       0.62      0.45      0.53        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.33      0.33      0.33         3\n",
      "          39       0.40      0.40      0.40         5\n",
      "          40       0.40      0.20      0.27        10\n",
      "          41       0.56      0.62      0.59         8\n",
      "          42       0.67      0.67      0.67         3\n",
      "          43       0.67      0.67      0.67         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.58      0.58      2246\n",
      "weighted avg       0.77      0.77      0.76      2246\n",
      "\n",
      "voting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.77      0.74      0.76       105\n",
      "           2       0.73      0.80      0.76        20\n",
      "           3       0.92      0.94      0.93       813\n",
      "           4       0.83      0.88      0.85       474\n",
      "           5       1.00      0.20      0.33         5\n",
      "           6       0.86      0.86      0.86        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.70      0.68      0.69        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.93      0.90      0.92        30\n",
      "          11       0.65      0.69      0.67        83\n",
      "          12       0.46      0.46      0.46        13\n",
      "          13       0.68      0.62      0.65        37\n",
      "          14       0.14      0.50      0.22         2\n",
      "          15       0.57      0.44      0.50         9\n",
      "          16       0.72      0.75      0.73        99\n",
      "          17       0.53      0.67      0.59        12\n",
      "          18       0.79      0.55      0.65        20\n",
      "          19       0.68      0.69      0.68       133\n",
      "          20       0.62      0.49      0.54        70\n",
      "          21       0.65      0.81      0.72        27\n",
      "          22       1.00      0.14      0.25         7\n",
      "          23       0.60      0.75      0.67        12\n",
      "          24       0.67      0.63      0.65        19\n",
      "          25       0.95      0.68      0.79        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       0.67      0.50      0.57         4\n",
      "          28       0.44      0.40      0.42        10\n",
      "          29       0.40      1.00      0.57         4\n",
      "          30       0.67      0.50      0.57        12\n",
      "          31       0.75      0.46      0.57        13\n",
      "          32       1.00      1.00      1.00        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       1.00      0.67      0.80         6\n",
      "          36       0.56      0.45      0.50        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.50      0.40      0.44         5\n",
      "          40       0.67      0.20      0.31        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       0.75      1.00      0.86         3\n",
      "          43       0.67      1.00      0.80         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.71      0.66      0.66      2246\n",
      "weighted avg       0.81      0.81      0.81      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline(x_train, y_train, x_test, y_test) # voca 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "logical-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.50      0.80      0.62       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.86      0.89      0.87       813\n",
      "           4       0.59      0.95      0.73       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.28      0.44        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.48      0.73      0.58        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       1.00      0.14      0.24        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.60      0.66      0.62        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.51      0.81      0.63       133\n",
      "          20       0.90      0.13      0.23        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       1.00      0.06      0.12        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.16      0.12      0.11      2246\n",
      "weighted avg       0.60      0.67      0.60      2246\n",
      "\n",
      "CNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70        12\n",
      "           1       0.63      0.86      0.73       105\n",
      "           2       0.91      0.50      0.65        20\n",
      "           3       0.91      0.89      0.90       813\n",
      "           4       0.74      0.92      0.82       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.86      0.86      0.86        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.57      0.21      0.31        38\n",
      "           9       0.82      0.92      0.87        25\n",
      "          10       0.96      0.80      0.87        30\n",
      "          11       0.54      0.76      0.63        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.69      0.59      0.64        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.67      0.79      0.72        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.55      0.60      0.57        20\n",
      "          19       0.56      0.80      0.66       133\n",
      "          20       0.79      0.33      0.46        70\n",
      "          21       0.78      0.67      0.72        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.67      0.33      0.44        12\n",
      "          24       0.67      0.11      0.18        19\n",
      "          25       0.86      0.77      0.81        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.33      0.20      0.25        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       1.00      0.15      0.27        13\n",
      "          32       1.00      0.70      0.82        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      0.71      0.83         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       1.00      0.17      0.29         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.44      0.48      2246\n",
      "weighted avg       0.76      0.77      0.75      2246\n",
      "\n",
      "logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.77      0.80      0.79       105\n",
      "           2       0.74      0.85      0.79        20\n",
      "           3       0.91      0.93      0.92       813\n",
      "           4       0.81      0.87      0.84       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.64      0.74      0.68        38\n",
      "           9       0.81      0.88      0.85        25\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       0.64      0.73      0.68        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.64      0.62      0.63        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.83      0.56      0.67         9\n",
      "          16       0.67      0.73      0.70        99\n",
      "          17       0.82      0.75      0.78        12\n",
      "          18       0.80      0.60      0.69        20\n",
      "          19       0.66      0.68      0.67       133\n",
      "          20       0.61      0.47      0.53        70\n",
      "          21       0.62      0.78      0.69        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.55      0.50      0.52        12\n",
      "          24       0.69      0.58      0.63        19\n",
      "          25       0.91      0.65      0.75        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.67      0.40      0.50        10\n",
      "          29       0.50      0.75      0.60         4\n",
      "          30       1.00      0.42      0.59        12\n",
      "          31       0.70      0.54      0.61        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       1.00      0.29      0.44         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.38      0.27      0.32        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.40      0.40      0.40         5\n",
      "          40       0.75      0.30      0.43        10\n",
      "          41       0.83      0.62      0.71         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.67      1.00      0.80         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.73      0.61      0.64      2246\n",
      "weighted avg       0.80      0.81      0.80      2246\n",
      "\n",
      "SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.72      0.72      0.72       105\n",
      "           2       0.60      0.75      0.67        20\n",
      "           3       0.90      0.90      0.90       813\n",
      "           4       0.81      0.84      0.82       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.86      0.86      0.86        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.61      0.66      0.63        38\n",
      "           9       0.77      0.80      0.78        25\n",
      "          10       0.77      0.80      0.79        30\n",
      "          11       0.64      0.73      0.69        83\n",
      "          12       0.40      0.31      0.35        13\n",
      "          13       0.59      0.54      0.56        37\n",
      "          14       1.00      0.50      0.67         2\n",
      "          15       0.50      0.44      0.47         9\n",
      "          16       0.66      0.70      0.68        99\n",
      "          17       0.60      0.25      0.35        12\n",
      "          18       0.87      0.65      0.74        20\n",
      "          19       0.61      0.65      0.63       133\n",
      "          20       0.45      0.43      0.44        70\n",
      "          21       0.55      0.78      0.65        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.54      0.58      0.56        12\n",
      "          24       0.57      0.42      0.48        19\n",
      "          25       0.85      0.55      0.67        31\n",
      "          26       1.00      0.75      0.86         8\n",
      "          27       1.00      0.50      0.67         4\n",
      "          28       0.44      0.40      0.42        10\n",
      "          29       0.22      0.50      0.31         4\n",
      "          30       0.62      0.42      0.50        12\n",
      "          31       0.67      0.31      0.42        13\n",
      "          32       0.89      0.80      0.84        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.50      0.57      0.53         7\n",
      "          35       1.00      0.50      0.67         6\n",
      "          36       0.56      0.45      0.50        11\n",
      "          37       0.50      1.00      0.67         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       0.50      0.60      0.55         5\n",
      "          40       0.38      0.30      0.33        10\n",
      "          41       0.36      0.50      0.42         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       0.75      1.00      0.86         6\n",
      "          44       0.80      0.80      0.80         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.66      0.58      0.59      2246\n",
      "weighted avg       0.77      0.77      0.77      2246\n",
      "\n",
      "DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.72      0.40      0.52       105\n",
      "           2       0.60      0.45      0.51        20\n",
      "           3       0.94      0.84      0.89       813\n",
      "           4       0.39      0.91      0.55       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       1.00      0.57      0.73        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.88      0.88      0.88        25\n",
      "          10       0.87      0.87      0.87        30\n",
      "          11       0.62      0.48      0.54        83\n",
      "          12       0.17      0.08      0.11        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.60      0.82      0.69        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.62      0.26      0.37       133\n",
      "          20       0.33      0.03      0.05        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       1.00      0.05      0.10        19\n",
      "          25       0.86      0.19      0.32        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.50      0.10      0.17        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.83      1.00      0.91         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.24      0.17      0.18      2246\n",
      "weighted avg       0.61      0.62      0.57      2246\n",
      "\n",
      "RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.42      0.33        12\n",
      "           1       0.42      0.78      0.55       105\n",
      "           2       0.44      0.35      0.39        20\n",
      "           3       0.84      0.90      0.87       813\n",
      "           4       0.68      0.84      0.75       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.86      0.43      0.57        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.59      0.53      0.56        38\n",
      "           9       0.71      0.40      0.51        25\n",
      "          10       0.89      0.53      0.67        30\n",
      "          11       0.57      0.69      0.62        83\n",
      "          12       0.33      0.15      0.21        13\n",
      "          13       0.46      0.32      0.38        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       1.00      0.11      0.20         9\n",
      "          16       0.70      0.67      0.68        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.60      0.45      0.51        20\n",
      "          19       0.62      0.64      0.63       133\n",
      "          20       0.46      0.33      0.38        70\n",
      "          21       0.65      0.41      0.50        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.75      0.25      0.38        12\n",
      "          24       0.33      0.05      0.09        19\n",
      "          25       0.87      0.42      0.57        31\n",
      "          26       1.00      0.12      0.22         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.33      0.25      0.29         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       1.00      0.30      0.46        10\n",
      "          33       1.00      0.20      0.33         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.33      0.09      0.14        11\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.25      0.12      0.17         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       1.00      0.33      0.50         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.70      2246\n",
      "   macro avg       0.54      0.31      0.36      2246\n",
      "weighted avg       0.69      0.70      0.68      2246\n",
      "\n",
      "GRBT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.80      0.68      0.73       105\n",
      "           2       0.70      0.70      0.70        20\n",
      "           3       0.90      0.90      0.90       813\n",
      "           4       0.76      0.83      0.79       474\n",
      "           5       0.14      0.20      0.17         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.64      0.66      0.65        38\n",
      "           9       0.91      0.84      0.87        25\n",
      "          10       0.87      0.87      0.87        30\n",
      "          11       0.62      0.66      0.64        83\n",
      "          12       0.46      0.46      0.46        13\n",
      "          13       0.55      0.43      0.48        37\n",
      "          14       0.08      0.50      0.14         2\n",
      "          15       0.33      0.22      0.27         9\n",
      "          16       0.72      0.77      0.75        99\n",
      "          17       0.33      0.33      0.33        12\n",
      "          18       0.61      0.55      0.58        20\n",
      "          19       0.71      0.65      0.68       133\n",
      "          20       0.56      0.44      0.50        70\n",
      "          21       0.67      0.67      0.67        27\n",
      "          22       0.50      0.14      0.22         7\n",
      "          23       0.36      0.42      0.38        12\n",
      "          24       0.71      0.63      0.67        19\n",
      "          25       0.91      0.65      0.75        31\n",
      "          26       0.75      0.75      0.75         8\n",
      "          27       0.40      0.50      0.44         4\n",
      "          28       0.38      0.30      0.33        10\n",
      "          29       0.22      0.50      0.31         4\n",
      "          30       0.38      0.42      0.40        12\n",
      "          31       0.60      0.46      0.52        13\n",
      "          32       0.88      0.70      0.78        10\n",
      "          33       0.71      1.00      0.83         5\n",
      "          34       0.50      0.29      0.36         7\n",
      "          35       1.00      0.50      0.67         6\n",
      "          36       0.67      0.55      0.60        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.25      0.33      0.29         3\n",
      "          39       0.25      0.20      0.22         5\n",
      "          40       0.71      0.50      0.59        10\n",
      "          41       0.44      0.50      0.47         8\n",
      "          42       0.75      1.00      0.86         3\n",
      "          43       0.50      0.67      0.57         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.60      0.59      0.58      2246\n",
      "weighted avg       0.77      0.77      0.77      2246\n",
      "\n",
      "voting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.80      0.77      0.79       105\n",
      "           2       0.71      0.85      0.77        20\n",
      "           3       0.92      0.94      0.93       813\n",
      "           4       0.82      0.88      0.85       474\n",
      "           5       0.33      0.20      0.25         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       0.67      0.67      0.67         3\n",
      "           8       0.72      0.68      0.70        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.93      0.90      0.92        30\n",
      "          11       0.67      0.70      0.68        83\n",
      "          12       0.60      0.46      0.52        13\n",
      "          13       0.68      0.62      0.65        37\n",
      "          14       0.12      0.50      0.20         2\n",
      "          15       0.67      0.44      0.53         9\n",
      "          16       0.74      0.74      0.74        99\n",
      "          17       0.57      0.67      0.62        12\n",
      "          18       0.72      0.65      0.68        20\n",
      "          19       0.73      0.68      0.71       133\n",
      "          20       0.61      0.49      0.54        70\n",
      "          21       0.66      0.78      0.71        27\n",
      "          22       0.50      0.14      0.22         7\n",
      "          23       0.57      0.67      0.62        12\n",
      "          24       0.75      0.63      0.69        19\n",
      "          25       0.96      0.74      0.84        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       0.67      0.50      0.57         4\n",
      "          28       0.44      0.40      0.42        10\n",
      "          29       0.50      0.75      0.60         4\n",
      "          30       0.62      0.42      0.50        12\n",
      "          31       0.75      0.69      0.72        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.71      1.00      0.83         5\n",
      "          34       1.00      0.43      0.60         7\n",
      "          35       1.00      0.50      0.67         6\n",
      "          36       0.45      0.45      0.45        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.25      0.20      0.22         5\n",
      "          40       0.80      0.40      0.53        10\n",
      "          41       0.67      0.50      0.57         8\n",
      "          42       0.75      1.00      0.86         3\n",
      "          43       0.71      0.83      0.77         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.71      0.66      0.66      2246\n",
      "weighted avg       0.82      0.82      0.81      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline(x_train_2, y_train_2, x_test_2, y_test_2) # voca 5,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-beauty",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-litigation",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 4. 딥러닝 모델과 비교해 보기</span>\n",
    "---\n",
    "위 과정을 통해 나온 최적의 모델과 단어 수 조건에서, 본인이 선택한 다른 모델을 적용한 결과와 비교해 봅시다. 감정분석 등에 사용했던 RNN이나 1-D CNN 등의 딥러닝 모델 중 하나를 선택해서 오늘 사용했던 데이터셋을 학습해 보고 나오는 결과를 비교해 봅시다. 단, 공정한 비교를 위해 이때 Word2Vec 등의 pretrained model은 사용하지 않도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-parent",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dense-respondent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(100, 100), random_state=100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "(tfidfv, tfidfv_test) = tfidf(x_train_2,x_test_2)\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, 100), random_state=100)\n",
    "clf.fit(tfidfv, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "disabled-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70        12\n",
      "           1       0.77      0.70      0.73       105\n",
      "           2       0.70      0.70      0.70        20\n",
      "           3       0.91      0.92      0.92       813\n",
      "           4       0.78      0.88      0.83       474\n",
      "           5       0.50      0.20      0.29         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.69      0.71      0.70        38\n",
      "           9       0.76      0.88      0.81        25\n",
      "          10       0.90      0.87      0.88        30\n",
      "          11       0.65      0.80      0.72        83\n",
      "          12       0.38      0.23      0.29        13\n",
      "          13       0.61      0.59      0.60        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.67      0.22      0.33         9\n",
      "          16       0.70      0.72      0.71        99\n",
      "          17       0.50      0.25      0.33        12\n",
      "          18       0.86      0.60      0.71        20\n",
      "          19       0.65      0.69      0.67       133\n",
      "          20       0.64      0.59      0.61        70\n",
      "          21       0.73      0.70      0.72        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.44      0.33      0.38        12\n",
      "          24       0.69      0.58      0.63        19\n",
      "          25       0.95      0.68      0.79        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       0.80      1.00      0.89         4\n",
      "          28       0.36      0.40      0.38        10\n",
      "          29       0.57      1.00      0.73         4\n",
      "          30       1.00      0.58      0.74        12\n",
      "          31       0.88      0.54      0.67        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.71      0.45      0.56        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.67      0.20      0.31        10\n",
      "          41       0.43      0.38      0.40         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.67      1.00      0.80         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.80      2246\n",
      "   macro avg       0.70      0.60      0.63      2246\n",
      "weighted avg       0.79      0.80      0.79      2246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aiffel-dj49/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_2, clf.predict(tfidfv_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-buddy",
   "metadata": {},
   "source": [
    "## <span style=\"color:#124445\">Step 5. 루브릭 평가</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-attribute",
   "metadata": {},
   "source": [
    "|평가문항|상세기준|\n",
    "|-------|--------|\n",
    "|1. 분류 모델의 accuracy가 기준 이상 높게 나왔는가?|3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.|\n",
    "|2. 분류 모델의 F1 score가 기준 이상 높게 나왔는가?|Vocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.|\n",
    "|3. 생성모델의 metric(BLEU 등) 기준 이상 높은 성능이 확인되었는가?|동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-onion",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-livestock",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2C786C\">Step 6. 회고</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-group",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-lawyer",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
